{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a2fdafa-89ff-46d0-8214-7ea0d55c498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preparing features...\n",
      "\n",
      "Evaluating different numbers of clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 2, DB Index: 1.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 3, DB Index: 1.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 4, DB Index: 1.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 5, DB Index: 1.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 6, DB Index: 1.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 7, DB Index: 1.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 8, DB Index: 1.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 9, DB Index: 1.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 10, DB Index: 1.040\n",
      "\n",
      "Optimal clusters: 9\n",
      "\n",
      "Performing final clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing clusters...\n",
      "Creating visualizations...\n",
      "\n",
      "Final DB Index: 1.022951986409254\n",
      "\n",
      "Cluster Summary:\n",
      "         CustomerCount  AvgTrans  AvgSpend  AvgTransVal  AvgQty  \\\n",
      "Cluster                                                           \n",
      "0                   29      6.97   4931.24       717.09   17.38   \n",
      "1                   24      2.38   1657.32       715.89    5.75   \n",
      "2                   19      5.74   5486.41       964.90   18.68   \n",
      "3                   15      3.40   3736.68      1108.35    9.80   \n",
      "4                   16      2.56    742.27       280.30    4.38   \n",
      "5                   16      8.88   6875.24       782.19   24.75   \n",
      "6                   15      3.40   2101.49       634.33   11.13   \n",
      "7                   46      4.72   2961.49       628.34   11.41   \n",
      "8                   19      6.84   3015.29       446.04   12.37   \n",
      "\n",
      "         AvgQtyPerTrans  \n",
      "Cluster                  \n",
      "0                  2.51  \n",
      "1                  2.41  \n",
      "2                  3.26  \n",
      "3                  2.89  \n",
      "4                  1.67  \n",
      "5                  2.79  \n",
      "6                  3.37  \n",
      "7                  2.42  \n",
      "8                  1.81  \n",
      "\n",
      "Results saved to:\n",
      "- customerClusts.csv (all customers with their cluster assignments)\n",
      "- clustSummary.csv (summary stats for each cluster)\n",
      "- clustAnalysis.png (visualization plots)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def loadData():\n",
    "    try:\n",
    "        c = pd.read_csv('Customers.csv')\n",
    "        t = pd.read_csv('Transactions.csv')\n",
    "        p = pd.read_csv('Products.csv')\n",
    "        return c, t, p\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None, None\n",
    "def prepareFeatures(tDf):\n",
    "    cFeat = tDf.groupby('CustomerID').agg({\n",
    "        'TransactionID': 'count',\n",
    "        'TotalValue': ['sum', 'mean'],\n",
    "        'Quantity': ['sum', 'mean']\n",
    "    }).reset_index()\n",
    "    cFeat.columns = [\n",
    "        'CustomerID',\n",
    "        'transCount',\n",
    "        'totalSpend',\n",
    "        'avgTransVal',\n",
    "        'totalQty',\n",
    "        'avgQty'\n",
    "    ]   \n",
    "    return cFeat\n",
    "def performClustering(fDf, nClust):\n",
    "    fForClust = fDf.drop('CustomerID', axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    fScaled = scaler.fit_transform(fForClust)\n",
    "    kmeans = KMeans(n_clusters=nClust, random_state=42, n_init=10)\n",
    "    clustLabels = kmeans.fit_predict(fScaled)\n",
    "    dbIdx = davies_bouldin_score(fScaled, clustLabels)\n",
    "    fDf['Cluster'] = clustLabels\n",
    "    return fDf, dbIdx, kmeans.cluster_centers_\n",
    "def analyzeClusters(fDf):\n",
    "    cSummary = fDf.groupby('Cluster').agg({\n",
    "        'CustomerID': 'count',\n",
    "        'transCount': 'mean',\n",
    "        'totalSpend': 'mean',\n",
    "        'avgTransVal': 'mean',\n",
    "        'totalQty': 'mean',\n",
    "        'avgQty': 'mean'\n",
    "    }).round(2) \n",
    "    cSummary.columns = [\n",
    "        'CustomerCount',\n",
    "        'AvgTrans',\n",
    "        'AvgSpend',\n",
    "        'AvgTransVal',\n",
    "        'AvgQty',\n",
    "        'AvgQtyPerTrans'\n",
    "    ]\n",
    "    return cSummary\n",
    "def createVisualizations(fDf):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(fDf['totalSpend'], \n",
    "               fDf['transCount'], \n",
    "               c=fDf['Cluster'], \n",
    "               cmap='viridis')\n",
    "    plt.xlabel('Total Spend')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.title('Clusters by Spend and Trans Count')  \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(fDf['avgTransVal'], \n",
    "               fDf['totalQty'], \n",
    "               c=fDf['Cluster'], \n",
    "               cmap='viridis')\n",
    "    plt.xlabel('Avg Trans Value')\n",
    "    plt.ylabel('Total Quantity')\n",
    "    plt.title('Clusters by Trans Value and Qty')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    clustSizes = fDf['Cluster'].value_counts().sort_index()\n",
    "    clustSizes.plot(kind='bar')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('No. of Customers')\n",
    "    plt.title('Cluster Sizes')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('clustAnalysis.png')\n",
    "    plt.close()\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    cDf, tDf, pDf = loadData()\n",
    "    if cDf is None:\n",
    "        return\n",
    "    print(\"Preparing features...\")\n",
    "    fDf = prepareFeatures(tDf)\n",
    "    nClustRange = range(2, 11)\n",
    "    dbScores = []\n",
    "    print(\"\\nEvaluating different numbers of clusters...\")\n",
    "    for n in nClustRange:\n",
    "        _, dbIdx, _ = performClustering(fDf.copy(), n)\n",
    "        dbScores.append(dbIdx)\n",
    "        print(f\"Clusters: {n}, DB Index: {dbIdx:.3f}\") \n",
    "    optClust = nClustRange[np.argmin(dbScores)]\n",
    "    print(f\"\\nOptimal clusters: {optClust}\")\n",
    "    print(\"\\nPerforming final clustering...\")\n",
    "    clustDf, finalDbIdx, clustCenters = performClustering(fDf, optClust)\n",
    "    print(\"\\nAnalyzing clusters...\")\n",
    "    clustSummary = analyzeClusters(clustDf)\n",
    "    print(\"Creating visualizations...\")\n",
    "    createVisualizations(clustDf)\n",
    "    print(\"\\nFinal DB Index:\", finalDbIdx)\n",
    "    print(\"\\nCluster Summary:\")\n",
    "    print(clustSummary)\n",
    "    clustDf.to_csv('customerClusts.csv', index=False)\n",
    "    clustSummary.to_csv('clustSummary.csv')\n",
    "    print(\"\\nResults saved to:\")\n",
    "    print(\"- customerClusts.csv (all customers with their cluster assignments)\")\n",
    "    print(\"- clustSummary.csv (summary stats for each cluster)\")\n",
    "    print(\"- clustAnalysis.png (visualization plots)\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb6c5d-ba9c-4efe-843c-71ae8706694b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
